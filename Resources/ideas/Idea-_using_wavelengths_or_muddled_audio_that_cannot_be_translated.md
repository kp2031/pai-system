---
migrated: 2025-09-20T01:58:10.389284
source: apple-notes-exporter
original_path: Backup/iCloud/Notes/Idea- using wavelengths or muddled audio that cannot be translated….md
vault_folder: Resources/ideas
---
# Idea: using wavelengths or muddled audio that cannot be translated…

Idea: using wavelengths or muddled audio that cannot be translated into copyright information or sensitive material to give feedback on how a conversation is going or how a conversation went

The hypothesis and scenario that I have is that conversations between a boss and employee is highly sensitive, but the employee wants feedback on how that conversation went without directly recording the conversation how much feedback and how accurate can the feedback be? If for example, the Apple Watch could record the conversation between an employee and their boss without capturing the words that were said, and rather the tone and emotion of what was said through a censored or filtered audio signal, which would keep the content of the conversation private while providing feedback on how the conversation went

A great use case for this would be for preparation for an employee to ask for a raise

And then feedback about how that conversation went

Use AI text to speech technology to generate thousands of interactions and conversations between two people, employee and boss in various situations and scenarios and then muddled the audio so that sensitive information isn’t able to be extracted and then analyze the muddled audio and then see if the recommendations and predictions based on the muddled audio align with the recommendation from the unmuzzled audio
